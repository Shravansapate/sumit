#%%
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
#%%
def load_and_prepare_data(file_path):
    data = pd.read_csv(file_path)
    print(f"Missing values:\n{data.isnull().sum()}")
    print(f"\nBasic statistics:\n{data.describe()}")
    X = data.drop('price', axis=1)
    y = data['price']
    return X, y
#%%
def create_preprocessing_pipeline(X):
    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns
    categorical_features = X.select_dtypes(include=['object', 'bool']).columns
    numerical_transformer = StandardScaler()
    categorical_transformer = OneHotEncoder(handle_unknown='ignore')
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, numerical_features),
            ('cat', categorical_transformer, categorical_features)
        ]
    )
    return preprocessor
#%%
def build_and_evaluate_decision_tree(X, y, preprocessor):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    base_model = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', DecisionTreeRegressor(random_state=42))
    ])
    param_grid = {
        'regressor__max_depth': [None, 5, 10, 15, 20],
        'regressor__min_samples_split': [2, 5, 10],
        'regressor__min_samples_leaf': [1, 2, 4],
        'regressor__max_features': ['auto', 'sqrt', 'log2']
    }
    grid_search = GridSearchCV(
        base_model,
        param_grid,
        cv=5,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=1
    )
    print("Performing grid search for hyperparameter tuning...")
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    print(f"\nBest parameters: {best_params}")
    y_pred = best_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    results = {
        'model': best_model,
        'best_params': best_params,
        'mse': mse,
        'rmse': rmse,
        'r2': r2,
        'y_test': y_test,
        'y_pred': y_pred
    }
    print(f"\nDecision Tree Results:")
    print(f"MSE: {mse:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print(f"R²: {r2:.4f}")
    return results
#%%
def visualize_decision_tree(model, X, feature_names=None, max_depth=3):
    dt_model = model.named_steps['regressor']
    if feature_names is None:
        try:
            original_features = []
            for name, transformer, columns in model.named_steps['preprocessor'].transformers_:
                if name == 'num':
                    original_features.extend(columns)
                else:
                    for col in columns:
                        cat_features = [f"{col}_{category}" for category in 
                                       transformer.categories_[list(columns).index(col)]]
                        original_features.extend(cat_features)
            feature_names = original_features
        except:
            feature_names = [f"feature_{i}" for i in range(X.shape[1])]
    plt.figure(figsize=(20, 10))
    plot_tree(
        dt_model,
        max_depth=max_depth,
        feature_names=feature_names,
        filled=True,
        rounded=True,
        fontsize=10
    )
    plt.title(f"Decision Tree (Limited to Depth {max_depth})")
    plt.tight_layout()
    plt.show()
#%%
def visualize_results(results):
    plt.figure(figsize=(10, 6))
    plt.scatter(results['y_test'], results['y_pred'], alpha=0.5)
    plt.plot([results['y_test'].min(), results['y_test'].max()], 
             [results['y_test'].min(), results['y_test'].max()], 'r--')
    plt.xlabel('Actual Price')
    plt.ylabel('Predicted Price')
    plt.title(f'Decision Tree: Actual vs Predicted Prices (R² = {results["r2"]:.4f})')
    plt.tight_layout()
    plt.show()
#%%
def analyze_feature_importance(model, X):
    dt_model = model.named_steps['regressor']
    feature_names = []
    try:
        for name, transformer, columns in model.named_steps['preprocessor'].transformers_:
            if name == 'num':
                feature_names.extend(columns)
            else:
                for col in columns:
                    cat_features = [f"{col}_{category}" for category in 
                                   transformer.categories_[list(columns).index(col)]]
                    feature_names.extend(cat_features)
    except:
        feature_names = [f"feature_{i}" for i in range(len(dt_model.feature_importances_))]
    importances = dt_model.feature_importances_
    if len(importances) == len(feature_names):
        importance_df = pd.DataFrame({
            'Feature': feature_names,
            'Importance': importances
        }).sort_values('Importance', ascending=False)
        plt.figure(figsize=(12, 8))
        plt.barh(importance_df['Feature'][:15], importance_df['Importance'][:15])
        plt.xlabel('Importance')
        plt.ylabel('Feature')
        plt.title('Top 15 Feature Importances')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()
        return importance_df
    else:
        print("Feature names and importances lengths don't match.")
        print(f"Features: {len(feature_names)}, Importances: {len(importances)}")
        return None
#%%
def predict_house_price(model, new_data):
    prediction = model.predict(new_data)[0]
    return prediction
#%%
def main(file_path):
    print("Loading and preparing data...")
    X, y = load_and_prepare_data(file_path)
    print("\nCreating preprocessing pipeline...")
    preprocessor = create_preprocessing_pipeline(X)
    print("\nBuilding and evaluating decision tree model...")
    results = build_and_evaluate_decision_tree(X, y, preprocessor)
    print("\nVisualizing results...")
    visualize_results(results)
    print("\nVisualizing decision tree...")
    visualize_decision_tree(results['model'], X, max_depth=3)
    print("\nAnalyzing feature importance...")
    importance_df = analyze_feature_importance(results['model'], X)
    print("\nExample of making a new prediction:")
    new_house = pd.DataFrame({
        'area': [2500],
        'bedrooms': [3],
        'bathrooms': [2],
        'stories': [2],
        'mainroad': ['yes'],
        'guestroom': ['no'],
        'basement': ['yes'],
        'hotwaterheating': ['no'],
        'airconditioning': ['yes'],
        'parking': [1],
        'prefarea': ['yes'],
        'furnishingstatus': ['semi-furnished']
    })
    predicted_price = predict_house_price(results['model'], new_house)
    print(f"Predicted price for the sample house: ${predicted_price:.2f}")
    return results, importance_df
#%%
if __name__ == "__main__":
    file_path = "Housing.csv"  # Updated to use your specific CSV filename
    try:
        results, importance_df = main(file_path)
        print("\nProcess completed successfully!")
    except FileNotFoundError:
        print(f"\nFile not found: {file_path}")
        print("Please make sure the file exists and the path is correct.")
        print("Alternatively, you can create a sample dataset to test the model.")
        print("\nCreating a sample dataset for demonstration...")
        np.random.seed(42)
        n_samples = 100
        sample_data = pd.DataFrame({
            'price': np.random.normal(5000000, 1000000, n_samples),
            'area': np.random.normal(2000, 500, n_samples),
            'bedrooms': np.random.choice([2, 3, 4, 5], n_samples),
            'bathrooms': np.random.choice([1, 2, 3], n_samples),
            'stories': np.random.choice([1, 2, 3], n_samples),
            'mainroad': np.random.choice(['yes', 'no'], n_samples),
            'guestroom': np.random.choice(['yes', 'no'], n_samples),
            'basement': np.random.choice(['yes', 'no'], n_samples),
            'hotwaterheating': np.random.choice(['yes', 'no'], n_samples),
            'airconditioning': np.random.choice(['yes', 'no'], n_samples),
            'parking': np.random.choice([0, 1, 2], n_samples),
            'prefarea': np.random.choice(['yes', 'no'], n_samples),
            'furnishingstatus': np.random.choice(['unfurnished', 'semi-furnished', 'furnished'], n_samples)
        })
        sample_data['price'] = (
            sample_data['area'] * 1000 + 
            sample_data['bedrooms'] * 200000 + 
            sample_data['bathrooms'] * 300000 + 
            (sample_data['mainroad'] == 'yes') * 500000 +
            (sample_data['airconditioning'] == 'yes') * 300000 +
            (sample_data['prefarea'] == 'yes') * 700000 +
            np.random.normal(0, 300000, n_samples)
        )
        sample_file_path = "sample_housing_data.csv"
        sample_data.to_csv(sample_file_path, index=False)
        print(f"\nRunning with sample data from {sample_file_path}...")
        results, importance_df = main(sample_file_path)
        print("\nProcess completed successfully with sample data!")
# %%
